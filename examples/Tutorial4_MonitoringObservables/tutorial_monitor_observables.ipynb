{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training while monitoring observables\n",
    "\n",
    "As seen in the first tutorial that went through reconstructing the wavefunction describing the TFIM with 10 sites at its critical point, the user can evaluate the training in real time with the *MetricEvaluator* and custom functions. What is most likely more impactful in many cases is to calculate an observable, like the energy, during the training process. This is slightly more computationally involved than using the *MetricEvaluator* to evaluate functions because observables require that samples be drawn from the RBM. \n",
    "\n",
    "Luckily, qucumber also has a module very similar to the *MetricEvaluator*, but for observables. This is called the *ObservableEvaluator*. The following implements the *ObservableEvaluator* to calculate the energy during the training on the TFIM data in the first tutorial. We will use the same hyperparameters as before.\n",
    "\n",
    "It is assumed that the user has worked through tutorial 3 beforehand. Recall that *quantum_ising_chain.py* contains the *TFIMChainEnergy* class that inherits from the *Observable* module. The exact ground-state energy is -1.2381."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qucumber.nn_states import PositiveWaveFunction\n",
    "from qucumber.callbacks import ObservableEvaluator\n",
    "\n",
    "import qucumber.utils.data as data\n",
    "\n",
    "from quantum_ising_chain import TFIMChainEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.load_data(\n",
    "    os.path.join(\"..\", \"Tutorial1_TrainPosRealWaveFunction\", \"tfim1d_data.txt\")\n",
    ")[0]\n",
    "\n",
    "nv = train_data.shape[-1]\n",
    "nh = nv\n",
    "\n",
    "nn_state = PositiveWaveFunction(num_visible=nv, num_hidden=nh)\n",
    "\n",
    "epochs = 1000\n",
    "pbs = 100  # pos_batch_size\n",
    "nbs = 200  # neg_batch_size\n",
    "lr = 0.01\n",
    "k = 10\n",
    "\n",
    "log_every = 100\n",
    "\n",
    "h = 1\n",
    "num_samples = 10000\n",
    "burn_in = 100\n",
    "steps = 100\n",
    "\n",
    "tfim_energy = TFIMChainEnergy(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the *ObservableEvaluator* can be called. The *ObservableEvaluator* requires the following arguments.\n",
    "\n",
    "1. **log_every**: the frequency of the training evaluators being calculated is controlled by the *log_every* argument (e.g. *log_every* = 200 means that the *MetricEvaluator* will update the user every 200 epochs)\n",
    "2. A list of *Observable* objects you would like to reference to evaluate the training (arguments required for generating samples to calculate the observables are keyword arguments placed after the list)\n",
    "\n",
    "The following additional arguments are needed to calculate the statistics on the generated samples during training (these are the arguments of the *statistics* function in the *Observable* module, minus the *nn_state* argument; this gets passed in as an argument to *fit*). \n",
    "\n",
    "- **num_samples**: the number of samples to generate internally\n",
    "- **num_chains**: the number of Markov chains to run in parallel (default = 0)\n",
    "- **burn_in**: the number of Gibbs steps to perform before recording any samples (default = 1000)\n",
    "- **steps**: the number of Gibbs steps to perform between each sample (default = 1)\n",
    "\n",
    "The training evaluators can be printed out via the *verbose=True* statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ObservableEvaluator(\n",
    "        log_every,\n",
    "        [tfim_energy],\n",
    "        verbose=True,\n",
    "        num_samples=num_samples,\n",
    "        burn_in=burn_in,\n",
    "        steps=steps,\n",
    "    )\n",
    "]\n",
    "\n",
    "nn_state.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    pos_batch_size=pbs,\n",
    "    neg_batch_size=nbs,\n",
    "    lr=lr,\n",
    "    k=k,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *callbacks* list returns a list of dictionaries. The mean, standard error and the variance at each epoch can be accessed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = callbacks[0].TFIMChainEnergy.mean\n",
    "errors = callbacks[0].TFIMChainEnergy.std_error\n",
    "variance = callbacks[0].TFIMChainEnergy.variance\n",
    "# Please note that the name of the observable class that the user makes must be what comes after callbacks[0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the energy as a function of the training cycle is presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = np.arange(log_every, epochs + 1, log_every)\n",
    "\n",
    "E0 = -1.2381\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.plot(epoch, energies, color=\"red\")\n",
    "ax.set_xlim(log_every, epochs)\n",
    "ax.axhline(E0, color=\"black\")\n",
    "ax.fill_between(epoch, energies - errors, energies + errors, alpha=0.2, color=\"black\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Energy\")\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
